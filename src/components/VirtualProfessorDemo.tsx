
import { useState } from "react";
import { Dialog, DialogContent, DialogHeader, DialogTitle } from "@/components/ui/dialog";
import { Button } from "@/components/ui/button";
import { BookOpen } from "lucide-react";
import { extractTextFromPDF } from "../utils/pdfUtils";
import { createTextChunks } from "../utils/chunkingUtils";
import { createEmbeddings, findRelevantChunks } from "../utils/embeddingUtils";
import { createOpenAIEmbeddings, findRelevantChunksOpenAI } from "../utils/openaiEmbeddingUtils";
import { useAudioRecording } from "../hooks/useAudioRecording";
import { transcribeAudio } from "../utils/aiUtils";
import { askOpenAIPdfProfessor } from "../utils/openaiRagUtils";
import { askLocalPdfProfessor } from "../utils/localRagUtils";
import ApiKeyModal from "./VirtualProfessorDemo/ApiKeyModal";
import PdfUploadStep from "./VirtualProfessorDemo/PdfUploadStep";
import ProfessorChatStep from "./VirtualProfessorDemo/ProfessorChatStep";

interface VirtualProfessorDemoProps {
  isOpen: boolean;
  onClose: () => void;
}

interface ChatMessage {
  role: "user" | "professor";
  content: string;
  timestamp: Date;
  sources?: string[];
}

const VirtualProfessorDemo = ({ isOpen, onClose }: VirtualProfessorDemoProps) => {
  const [step, setStep] = useState(0);
  const [file, setFile] = useState<File | null>(null);
  const [isProcessing, setIsProcessing] = useState(false);
  const [extractedText, setExtractedText] = useState("");
  const [chunks, setChunks] = useState<string[]>([]);
  const [embeddings, setEmbeddings] = useState<number[][]>([]);
  const [messages, setMessages] = useState<ChatMessage[]>([]);
  const [currentQuestion, setCurrentQuestion] = useState("");
  const [isApiKeyModal, setIsApiKeyModal] = useState(false);
  const [processingStep, setProcessingStep] = useState("");

  const { isRecording, startRecording, stopRecording, recordedAudio, resetRecording } = useAudioRecording();
  const [transcriptionStatus, setTranscriptionStatus] = useState<"" | "in_progress" | "done" | "error">("");
  const [lastTranscription, setLastTranscription] = useState<string>("");

  const [apiKey, setApiKey] = useState<string>(() => localStorage.getItem("openai-demo-key") || "");

  const handleFileUpload = async (event: React.ChangeEvent<HTMLInputElement>) => {
    const selectedFile = event.target.files?.[0];
    if (!selectedFile || selectedFile.type !== "application/pdf") {
      alert("Per favore carica un file PDF valido");
      return;
    }
    
    setFile(selectedFile);
    setIsProcessing(true);
    setProcessingStep("Estrazione testo dal PDF...");
    
    try {
      console.log('üöÄ [DEMO REALE] Iniziando elaborazione PDF per demo professore...');
      console.log('üìÑ [DEMO REALE] File:', selectedFile.name, selectedFile.size, 'bytes');
      
      // 1. Estrazione testo reale con PDF.js
      console.log('üì• [DEMO REALE] Chiamando extractTextFromPDF...');
      const text = await extractTextFromPDF(selectedFile);
      setExtractedText(text);
      console.log('‚úÖ [DEMO REALE] Testo estratto:', text.length, 'caratteri');
      console.log('üìñ [DEMO REALE] Preview testo:', text.substring(0, 200) + '...');
      
      // 2. Chunking semantico avanzato
      setProcessingStep("Suddivisione semantica intelligente...");
      const textChunks = await createTextChunks(text);
      setChunks(textChunks);
      console.log('‚úÖ Chunk creati:', textChunks.length);
      
      // 3. Creazione embedding con sistema robusto
      setProcessingStep("Generazione embedding vettoriali...");
      let chunkEmbeddings: number[][];
      
      try {
        console.log('üß† [LOCALE] Uso diretto HuggingFace embeddings (sempre funzionante)...');
        setProcessingStep("Generazione embedding locali...");
        chunkEmbeddings = await createEmbeddings(textChunks);
        console.log('‚úÖ [HUGGINGFACE] Embedding generati:', chunkEmbeddings.length);
      } catch (huggingFaceError) {
        console.log('‚ö†Ô∏è [FALLBACK] HuggingFace fallito, provo OpenAI se disponibile...');
        if (!apiKey.trim()) {
          throw new Error('üîë Sistema non disponibile. Configura API Key OpenAI o riprova.');
        }
        setProcessingStep("Tentativo embedding OpenAI...");
        chunkEmbeddings = await createOpenAIEmbeddings(apiKey, textChunks);
        console.log('‚úÖ [OPENAI FALLBACK] Embedding generati:', chunkEmbeddings.length);
      }
      
      setEmbeddings(chunkEmbeddings);
      
      // 4. Attivazione chat professore
      setStep(1);
      setMessages([
        {
          role: "professor",
          content: `üéì **Professore Universitario Virtuale Attivato**

üìö **Documento elaborato con successo:**
- **File:** "${selectedFile.name}"
- **Contenuto:** ${Math.round(text.length / 1000)}k caratteri analizzati
- **Sezioni semantiche:** ${textChunks.length} chunk intelligenti
- **Sistema RAG:** ${chunkEmbeddings.length} embedding vettoriali

üß† **Capacit√† attive:**
- Analisi approfondita dei contenuti
- Risposta a domande specifiche e complesse
- Correlazione tra diverse sezioni del documento
- Spiegazioni step-by-step di concetti difficili

üí° **Come interagire con me:**
- Fai domande specifiche sui contenuti del documento
- Chiedi spiegazioni di concetti complessi
- Richiedi correlazioni tra argomenti diversi
- Usa la registrazione vocale per domande naturali

**Sono pronto per le tue domande accademiche!** üéØ`,
          timestamp: new Date(),
        },
      ]);
      
    } catch (error) {
      console.error("‚ùå Errore elaborazione PDF:", error);
      alert(`‚ùå Errore nell'elaborazione del PDF:\n\n${error}\n\nSuggerimenti:\n‚Ä¢ PDF deve contenere testo leggibile\n‚Ä¢ File non protetto da password\n‚Ä¢ Dimensione ragionevole (<100MB)\n‚Ä¢ Formato PDF standard`);
      setFile(null);
    } finally {
      setIsProcessing(false);
      setProcessingStep("");
    }
  };

  const handleVoiceRecording = async () => {
    if (isRecording) {
      stopRecording();
    } else {
      resetRecording();
      setTimeout(() => {
        startRecording();
      }, 150);
    }
    setTranscriptionStatus("");
    setLastTranscription("");
  };

  const processVoiceQuestion = async () => {
    if (!recordedAudio) return;
    setTranscriptionStatus("in_progress");
    setIsProcessing(true);
    try {
      const transcription = await transcribeAudio(recordedAudio);
      setLastTranscription(transcription);
      setCurrentQuestion(transcription);
      setTranscriptionStatus("done");
      await askQuestion(transcription);
    } catch (error) {
      console.error("Errore trascrizione:", error);
      setTranscriptionStatus("error");
      alert("Errore nella trascrizione audio. Riprova.");
    } finally {
      setIsProcessing(false);
      resetRecording();
    }
  };

  const askQuestion = async (question: string) => {
    if (!question.trim() || chunks.length === 0) return;
    
    setMessages((prev) => [
      ...prev,
      { role: "user", content: question, timestamp: new Date() },
    ]);
    setIsProcessing(true);

    try {
      console.log('üéì Professore elabora:', question);
      
      // 1. Ricerca semantica sempre funzionante
      let relevantChunks: string[] = [];
      
      try {
        console.log('üîç [LOCALE] Ricerca semantica con HuggingFace...');
        relevantChunks = await findRelevantChunks(question, chunks, embeddings);
        console.log('üìö [HUGGINGFACE] Chunk rilevanti trovati:', relevantChunks.length);
      } catch (searchError) {
        console.log('‚ö†Ô∏è [FALLBACK RICERCA] HuggingFace fallito, provo OpenAI...');
        relevantChunks = await findRelevantChunksOpenAI(apiKey, question, chunks, embeddings);
        console.log('üìö [OPENAI FALLBACK] Chunk rilevanti trovati:', relevantChunks.length);
      }
      
      if (relevantChunks.length === 0) {
        setMessages((prev) => [
          ...prev,
          {
            role: "professor",
            content: `üîç **Non ho trovato informazioni specifiche nel documento per rispondere a questa domanda.**

**Possibili cause:**
‚Ä¢ L'argomento non √® trattato nel PDF caricato
‚Ä¢ La terminologia usata √® diversa da quella nel documento
‚Ä¢ La domanda √® troppo generica

**Suggerimenti:**
‚Ä¢ Riprova con parole chiave pi√π specifiche
‚Ä¢ Usa terminologia presente nel documento
‚Ä¢ Fai una domanda pi√π dettagliata

Posso aiutarti a esplorare i contenuti del documento se mi dai indicazioni pi√π precise! üìñ`,
            timestamp: new Date(),
          },
        ]);
        return;
      }

      // 2. Generazione risposta con sistema SEMPRE funzionante
      console.log('ü§ñ Chiamata Professore con', relevantChunks.length, 'chunk');
      let professorResponse: string;
      
      // Sistema prioritario: OpenAI se disponibile, altrimenti locale SEMPRE
      if (!apiKey.trim()) {
        console.log('üîß [LOCALE] Nessuna API Key - uso sistema locale diretto');
        professorResponse = await askLocalPdfProfessor(question, relevantChunks);
      } else {
        try {
          console.log('üéØ [OPENAI] Tentativo con GPT-4o...');
          professorResponse = await askOpenAIPdfProfessor(apiKey, question, relevantChunks);
          console.log('‚úÖ [OPENAI] Risposta generata con successo');
        } catch (openaiError: any) {
          console.log('‚ö†Ô∏è [FALLBACK AUTOMATICO] OpenAI fallito:', openaiError.message);
          
          // FALLBACK LOCALE IMMEDIATO per qualsiasi errore OpenAI
          console.log('üîÑ [LOCALE] Attivazione sistema locale...');
          professorResponse = await askLocalPdfProfessor(question, relevantChunks);
          console.log('‚úÖ [LOCALE] Risposta locale generata');
          
          // Aggiungi nota informativa se quota esaurita
          if (openaiError.message?.includes('QUOTA_EXCEEDED') || openaiError.message?.includes('quota')) {
            professorResponse += '\n\nüí° *Sistema locale attivato - OpenAI quota esaurita*';
          }
        }
      }
      
      setMessages((prev) => [
        ...prev,
        { 
          role: "professor", 
          content: professorResponse, 
          timestamp: new Date(),
          sources: relevantChunks.map((chunk, i) => `Sezione ${i + 1}: ${chunk.substring(0, 100)}...`)
        },
      ]);
      
    } catch (error) {
      console.error("‚ùå Errore professore:", error);
      
      // Sistema di emergenza: prova sempre il fallback locale
      try {
        console.log('üö® [EMERGENZA] Attivazione sistema locale di backup...');
        const emergencyResponse = await askLocalPdfProfessor(question, chunks.slice(0, 3));
        
        setMessages((prev) => [
          ...prev,
          {
            role: "professor",
            content: emergencyResponse + "\n\n‚ö†Ô∏è *Risposta generata con sistema locale (OpenAI non disponibile)*",
            timestamp: new Date(),
          },
        ]);
        
      } catch (localError) {
        console.error("‚ùå Anche il sistema locale ha fallito:", localError);
        
        setMessages((prev) => [
          ...prev,
          {
            role: "professor",
            content: `üîç **Analisi del documento completata**

Ho trovato alcune sezioni nel documento per la tua domanda:

${chunks.slice(0, 3).map((chunk, i) => `**Sezione ${i + 1}:**\n${chunk.substring(0, 300)}...\n`).join('\n')}

‚ö†Ô∏è *Sistema in modalit√† di emergenza - mostrando contenuti grezzi del documento*`,
            timestamp: new Date(),
          },
        ]);
      }
    } finally {
      setIsProcessing(false);
      setCurrentQuestion("");
    }
  };

  const handleClose = () => {
    setStep(0);
    setFile(null);
    setExtractedText("");
    setChunks([]);
    setEmbeddings([]);
    setMessages([]);
    setCurrentQuestion("");
    setIsProcessing(false);
    resetRecording();
    onClose();
  };

  const handleSaveApiKey = () => {
    if (apiKey.trim().length < 20) {
      alert("‚ö†Ô∏è API Key troppo corta. Inserisci una API Key OpenAI valida.");
      return;
    }
    localStorage.setItem("openai-demo-key", apiKey);
    setIsApiKeyModal(false);
    alert("‚úÖ API Key salvata! Ora puoi utilizzare il Professore Virtuale.");
  };

  return (
    <Dialog open={isOpen} onOpenChange={handleClose}>
      <DialogContent className="max-w-5xl max-h-[95vh] overflow-y-auto">
        <ApiKeyModal
          isOpen={isApiKeyModal}
          apiKey={apiKey}
          onApiKeyChange={setApiKey}
          onSave={handleSaveApiKey}
          onClose={() => setIsApiKeyModal(false)}
        />
        
        <DialogHeader>
          <div className="flex justify-between items-start">
            <DialogTitle className="text-2xl font-bold gradient-text flex items-center">
              <BookOpen className="mr-3 h-6 w-6" />
              üéì Professore Universitario Virtuale
            </DialogTitle>
            <Button
              size="sm"
              className={`ml-6 ${apiKey ? 'bg-green-100 hover:bg-green-200 text-green-800' : 'bg-orange-100 hover:bg-orange-200 text-orange-800'}`}
              onClick={() => setIsApiKeyModal(true)}
              variant="outline"
            >
              {apiKey ? "‚úÖ API Key Configurata" : "‚öôÔ∏è Configura API Key"}
            </Button>
          </div>
          <p className="text-muted-foreground text-lg">
            Sistema RAG <strong>REALE</strong>: <strong>PDF.js ‚Üí HuggingFace Embeddings ‚Üí GPT-4o ‚Üí Risposte Accademiche VERE</strong>
          </p>
          {!apiKey && (
            <div className="bg-orange-50 border border-orange-200 rounded-lg p-3 mt-2">
              <p className="text-orange-800 text-sm">
                ‚ö†Ô∏è <strong>API Key OpenAI richiesta:</strong> Per utilizzare il Professore Virtuale devi configurare la tua API Key OpenAI. Clicca su "Configura API Key" in alto a destra.
              </p>
            </div>
          )}
        </DialogHeader>
        
        <div className="space-y-6">
          {step === 0 ? (
            <PdfUploadStep
              file={file}
              isProcessing={isProcessing}
              onFileUpload={handleFileUpload}
              processingStep={processingStep}
            />
          ) : (
            <ProfessorChatStep
              file={file}
              chunks={chunks}
              isProcessing={isProcessing}
              messages={messages}
              isRecording={isRecording}
              recordedAudio={recordedAudio}
              transcriptionStatus={transcriptionStatus}
              lastTranscription={lastTranscription}
              currentQuestion={currentQuestion}
              onStartRecording={handleVoiceRecording}
              onStopRecording={handleVoiceRecording}
              onResetRecording={resetRecording}
              onProcessVoiceQuestion={processVoiceQuestion}
              setCurrentQuestion={setCurrentQuestion}
              onAskQuestion={askQuestion}
              hasApiKey={!!apiKey}
            />
          )}
        </div>
      </DialogContent>
    </Dialog>
  );
};

export default VirtualProfessorDemo;
